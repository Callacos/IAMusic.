import requests
import time
import pickle
import os
import hashlib

# Cache simple pour les requÃªtes Ollama
ollama_cache = {}
CACHE_FILE = os.path.join(os.path.dirname(__file__), "ollama_cache.pkl")

# Charger le cache s'il existe
try:
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, "rb") as f:
            ollama_cache = pickle.load(f)
        print(f"ğŸ“‚ Cache Ollama chargÃ© : {len(ollama_cache)} entrÃ©es")
except:
    print("âš ï¸ Cache Ollama non trouvÃ© ou invalide, dÃ©marrage avec un cache vide")

def save_cache():
    """Sauvegarde le cache des rÃ©ponses Ollama sur disque"""
    try:
        with open(CACHE_FILE, "wb") as f:
            pickle.dump(ollama_cache, f)
        print(f"ğŸ’¾ Cache Ollama sauvegardÃ© : {len(ollama_cache)} entrÃ©es")
    except Exception as e:
        print(f"âš ï¸ Erreur lors de la sauvegarde du cache : {e}")

def extract_keywords_with_ollama(user_phrase):
    """
    Utilise Ollama (Gemma 2B instruct) pour extraire des mots-clÃ©s musicaux d'une phrase utilisateur.
    """
    import requests, hashlib, time

    phrase_key = hashlib.md5(user_phrase.lower().encode()).hexdigest()
    if phrase_key in ollama_cache:
        print(f"ğŸ“ Cache utilisÃ© pour : '{user_phrase}'")
        return ollama_cache[phrase_key]

    try:
        print("ğŸ”„ VÃ©rification de la dispo dâ€™Ollama...")
        check = requests.get("http://localhost:11434/api/version", timeout=1)
        if check.status_code != 200:
            return None
        print("âœ… Ollama est dispo")

        prompt = f"""Give 1 to 3 short music-related **keywords**, comma-separated, that describe the **intention or emotion** behind this sentence:

"{user_phrase}"

 Respond ONLY with the keywords. No sentences, no quotes, no explanation.
Example: I need something relaxing â†’ relax, calm, chill
Keywords:"""


        payload = {
            "model": "gemma:2b-instruct",
            "prompt": prompt,
            "temperature": 0.2,
            "top_p": 1,
            "top_k": 40,
            "max_tokens": 20,
            "stream": False
        }

        print(f"ğŸ¤– Envoi Ã  Gemma : '{user_phrase}'")
        start = time.time()
        response = requests.post("http://localhost:11434/api/generate", json=payload, timeout=15)
        duration = time.time() - start
        print(f"â±ï¸ RÃ©ponse en {duration:.2f}s")

        if response.status_code == 200:
            raw = response.json().get("response", "").strip()
            print(f"ğŸ” RÃ©ponse brute : '{raw}'")

            for prefix in ["keywords:", "mots-clÃ©s :", "â†’", "- "]:
                if raw.lower().startswith(prefix):
                    raw = raw[len(prefix):].strip()

            keywords = [k.strip().lower() for k in raw.split(",") if len(k.strip()) > 1]
            keywords = list(dict.fromkeys(keywords))[:3]

            if keywords:
                ollama_cache[phrase_key] = keywords
                if len(ollama_cache) % 5 == 0:
                    save_cache()
                print(f"âœ… Mots-clÃ©s IA : {keywords}")
                return keywords
            else:
                print("âš ï¸ Aucun mot-clÃ© aprÃ¨s nettoyage")
                return None
        else:
            print(f"âŒ RÃ©ponse KO : {response.status_code}")
            return None

    except requests.exceptions.Timeout:
        print("â±ï¸ Timeout Ollama")
        return None
    except Exception as e:
        print(f"âŒ Erreur gÃ©nÃ©rale : {e}")
        return None

def warmup_ollama():
    """
    PrÃ©chauffe Ollama en effectuant une requÃªte simple.
    Ã€ utiliser au dÃ©marrage de l'application.
    """
    print("ğŸ”¥ PrÃ©chauffage d'Ollama...")
    try:
        # Simple requÃªte pour charger le modÃ¨le en mÃ©moire
        payload = {
            "model": "gemma:2b",
            "prompt": "Donne 3 mots-clÃ©s musicaux pour: dÃ©tente",
            "stream": False
        }
        
        start = time.time()
        response = requests.post(
            "http://localhost:11434/api/generate", 
            json=payload, 
            timeout=30
        )
        duration = time.time() - start
        
        if response.status_code == 200:
            print(f"âœ… Ollama prÃ©chauffÃ© en {duration:.2f} secondes")
            # Ajouter une entrÃ©e dans le cache pour "dÃ©tente"
            result = response.json()
            keywords_text = result.get('response', '').strip()
            keywords = [k.strip().lower() for k in keywords_text.split(',')]
            if keywords and len(keywords) > 0:
                cache_key = hashlib.md5("dÃ©tente".encode()).hexdigest()
                ollama_cache[cache_key] = keywords[:3]
            return True
        else:
            print(f"âŒ Ã‰chec du prÃ©chauffage : {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Erreur lors du prÃ©chauffage : {str(e)}")
        return False

# Si ce fichier est exÃ©cutÃ© directement, effectuer un test
if __name__ == "__main__":
    # PrÃ©chauffer Ollama
    warmup_ollama()
    
    # Tester l'extraction de mots-clÃ©s
    test_phrases = [
        "Je suis stressÃ© et j'ai besoin de me calmer",
        "Musique pour faire du sport",
        "Je veux danser toute la nuit"
    ]
    
    for phrase in test_phrases:
        print(f"\nğŸ§ª Test avec la phrase: '{phrase}'")
        keywords = extract_keywords_with_ollama(phrase)
        print(f"ğŸ“Š RÃ©sultat: {keywords}")
    
    # Sauvegarder le cache Ã  la fin
    save_cache()