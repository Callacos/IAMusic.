import requests
import time
import pickle
import os
import hashlib
import re
import nltk
from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()

# Cache simple pour les requ√™tes Ollama
ollama_cache = {}
CACHE_FILE = os.path.join(os.path.dirname(__file__), "ollama_cache.pkl")

# Charger le cache s'il existe
try:
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, "rb") as f:
            ollama_cache = pickle.load(f)
        print(f"üìÇ Cache Ollama charg√© : {len(ollama_cache)} entr√©es")
except:
    print("‚ö†Ô∏è Cache Ollama non trouv√© ou invalide, d√©marrage avec un cache vide")

def save_cache():
    """Sauvegarde le cache des r√©ponses Ollama sur disque"""
    try:
        with open(CACHE_FILE, "wb") as f:
            pickle.dump(ollama_cache, f)
        print(f"üíæ Cache Ollama sauvegard√© : {len(ollama_cache)} entr√©es")
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de la sauvegarde du cache : {e}")

def extract_keywords_with_ollama(user_phrase):
    """
    Utilise Ollama (Gemma 2B instruct) pour extraire des mots-cl√©s musicaux d'une phrase utilisateur.
    """
    import requests, hashlib, time

    phrase_key = hashlib.md5(user_phrase.lower().encode()).hexdigest()
    if phrase_key in ollama_cache:
        print(f"üìé Cache utilis√© pour : '{user_phrase}'")
        return ollama_cache[phrase_key]

    try:
        print("üîÑ V√©rification de la dispo d‚ÄôOllama...")
        check = requests.get("http://localhost:11434/api/version", timeout=1)
        if check.status_code != 200:
            return None
        print("‚úÖ Ollama est dispo")

        prompt = f"""Give 1 to 3 short music-related **keywords**, comma-separated, that describe the **intention or emotion** behind this sentence:

"{user_phrase}"

 Respond ONLY with the keywords. No sentences, no quotes, no explanation.
Example: I need something relaxing ‚Üí relax, calm, chill
Keywords:"""


        payload = {
            "model": "gemma:2b-instruct",
            "prompt": prompt,
            "temperature": 0.2,
            "top_p": 1,
            "top_k": 40,
            "max_tokens": 20,
            "stream": False
        }

        print(f"ü§ñ Envoi √† Gemma : '{user_phrase}'")
        start = time.time()
        response = requests.post("http://localhost:11434/api/generate", json=payload, timeout=15)
        duration = time.time() - start
        print(f"‚è±Ô∏è R√©ponse en {duration:.2f}s")

        if response.status_code == 200:
            raw = response.json().get("response", "").strip()
            raw = re.sub(r"\d+\.\s*", "", raw)  # Supprime "1. ", "2. " etc.
            raw = raw.replace("\n", ",")  # Remplace les sauts de ligne par des virgules
            print(f"üîç R√©ponse brute : '{raw}'")

            for prefix in ["keywords:", "mots-cl√©s :", "‚Üí", "- "]:
                if raw.lower().startswith(prefix):
                    raw = raw[len(prefix):].strip()

            if not raw.strip():
                print("‚ö†Ô∏è R√©ponse IA vide ou inutile")
                return None

            keywords = [lemmatizer.lemmatize(k.strip().lower(), pos='v') for k in raw.split(",") if len(k.strip()) > 1]
            keywords = list(dict.fromkeys(keywords))[:3]

            if keywords:
                ollama_cache[phrase_key] = keywords
                if len(ollama_cache) % 5 == 0:
                    save_cache()
                print(f"‚úÖ Mots-cl√©s IA : {keywords}")
                return keywords
            else:
                print("‚ö†Ô∏è Aucun mot-cl√© apr√®s nettoyage")
                return None
        else:
            print(f"‚ùå R√©ponse KO : {response.status_code}")
            return None

    except requests.exceptions.Timeout:
        print("‚è±Ô∏è Timeout Ollama")
        return None
    except Exception as e:
        print(f"‚ùå Erreur g√©n√©rale : {e}")
        return None

def warmup_ollama():
    """
    Pr√©chauffe Ollama en effectuant une requ√™te simple.
    √Ä utiliser au d√©marrage de l'application.
    """
    print("üî• Pr√©chauffage d'Ollama...")
    try:
        # Simple requ√™te pour charger le mod√®le en m√©moire
        payload = {
            "model": "gemma:2b",
            "prompt": "Donne 3 mots-cl√©s musicaux pour: d√©tente",
            "stream": False
        }
        
        start = time.time()
        response = requests.post(
            "http://localhost:11434/api/generate", 
            json=payload, 
            timeout=30
        )
        duration = time.time() - start
        
        if response.status_code == 200:
            print(f"‚úÖ Ollama pr√©chauff√© en {duration:.2f} secondes")
            # Ajouter une entr√©e dans le cache pour "d√©tente"
            result = response.json()
            keywords_text = result.get('response', '').strip()
            keywords = [k.strip().lower() for k in keywords_text.split(',')]
            if keywords and len(keywords) > 0:
                cache_key = hashlib.md5("d√©tente".encode()).hexdigest()
                ollama_cache[cache_key] = keywords[:3]
            return True
        else:
            print(f"‚ùå √âchec du pr√©chauffage : {response.status_code}")
            return False
    except Exception as e:
        print(f"‚ùå Erreur lors du pr√©chauffage : {str(e)}")
        return False

# Si ce fichier est ex√©cut√© directement, effectuer un test
if __name__ == "__main__":
    # Pr√©chauffer Ollama
    warmup_ollama()
    
    # Tester l'extraction de mots-cl√©s
    test_phrases = [
        "Je suis stress√© et j'ai besoin de me calmer",
        "Musique pour faire du sport",
        "Je veux danser toute la nuit"
    ]
    
    for phrase in test_phrases:
        print(f"\nüß™ Test avec la phrase: '{phrase}'")
        keywords = extract_keywords_with_ollama(phrase)
        print(f"üìä R√©sultat: {keywords}")
    
    # Sauvegarder le cache √† la fin
    save_cache()

# Dictionnaire de synonymes
synonym_map = {
    "bouger": "bouge",
    "boug√©": "bouge",
    "je veux bouge": "bouge",
    "danser": "bouge",
    "dance": "bouge",
    "rhythmic": "bouge",
    "calm": "relax",
    "chill": "relax",
    "peace": "relax",
    "relaxing": "relax",
    "tense": "stress",
    "anxious": "stress",
    "energetic": "√©nergie",
    "motivation": "√©nergie",
    "stress√©": "stress",
    "cri√©": "crier",
    "scream": "crier",
    "sport": "sport",
    "muscu": "sport",
    "musculation": "sport",
    "gym": "sport",
    "entrainement": "sport",
    "training": "sport",
    "park": "linkin park",
    "linkin": "linkin park",
    "taff": "travail",
    "boulot": "travail",
    
}

def normalize_keywords(keywords):
    """Normalise une liste de mots-cl√©s en appliquant lemmatisation et d√©doublonnage"""
    if not keywords:
        return []
    
    try:
        # Lemmatisation des mots-cl√©s
        lemmatized = []
        for k in keywords:
            try:
                lemmatized.append(lemmatizer.lemmatize(k.strip().lower(), pos='v'))
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur de lemmatisation pour '{k}': {e}")
                lemmatized.append(k.strip().lower())
        
        # Supprimer les doublons tout en pr√©servant l'ordre
        return list(dict.fromkeys(lemmatized))
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur dans normalize_keywords: {e}")
        # En cas d'erreur, retourner les mots-cl√©s originaux sans traitement
        return list(dict.fromkeys([k.strip().lower() for k in keywords]))